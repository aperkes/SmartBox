{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make markers\n",
    "\n",
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print these!\n",
      "Take a picture!\n"
     ]
    }
   ],
   "source": [
    "aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_250)\n",
    "\n",
    "fig = plt.figure()\n",
    "nx = 4\n",
    "ny = 3\n",
    "for i in range(1, nx*ny+1):\n",
    "    ax = fig.add_subplot(ny,nx, i)\n",
    "    img = aruco.drawMarker(aruco_dict,i, 700)\n",
    "    plt.imshow(img, cmap = cm.gray, interpolation = \"nearest\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.savefig(\"markers.pdf\")\n",
    "plt.show()\n",
    "\n",
    "print('Print these!')\n",
    "print('Take a picture!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv2.imread(\"tags.png\")\n",
    "plt.figure()\n",
    "plt.imshow(frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_250)\n",
    "parameters =  aruco.DetectorParameters_create()\n",
    "corners, ids, rejectedImgPoints = aruco.detectMarkers(gray, aruco_dict, parameters=parameters)\n",
    "frame_markers = aruco.drawDetectedMarkers(frame.copy(), corners, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(frame_markers)\n",
    "for i in range(len(ids)):\n",
    "    c = corners[i][0]\n",
    "    plt.plot([c[:, 0].mean()], [c[:, 1].mean()], \"o\", label = \"id={0}\".format(ids[i]))\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This works! \n",
    "## It needs to identify by ID, but that will be fairly easy. \n",
    "## I can practice this, but pretty quickly I should start working in the real space. \n",
    "## There will likely be some parameter and environmental tuning...\n",
    "\n",
    "screen_cap = cv2.VideoCapture(0)\n",
    "aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_250)\n",
    "parameters = aruco.DetectorParameters_create()\n",
    "import time\n",
    "\n",
    "draw = True\n",
    "t_start = time.time()\n",
    "t_end = t_start + 15\n",
    "while time.time() < t_end:\n",
    "    ret, frame = screen_cap.read()\n",
    "    #frame = cv2.imread('tags.png')\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    corners, ids, rejectedImgPoints = aruco.detectMarkers(gray, aruco_dict, parameters=parameters)\n",
    "    frame_markers = aruco.drawDetectedMarkers(frame.copy(), corners, ids)\n",
    "\n",
    "    if len(corners) == 12 and draw == True:\n",
    "        x0,y0 = tuple(corners[np.where(ids == 1)[0][0]][0,0])\n",
    "        x1 = corners[np.where(ids == 12)[0][0]][0,0,0]\n",
    "        y1 = corners[np.where(ids == 5)[0][0]][0,0,1]\n",
    "        y2 = corners[np.where(ids == 10)[0][0]][0,0,1]\n",
    "        x2 = corners[np.where(ids == 2)[0][0]][0,0,0]\n",
    "        y3 = corners[np.where(ids == 9)[0][0]][0,0,1]\n",
    "        x3 = corners[np.where(ids == 8)[0][0]][0,0,0]\n",
    "        cv2.rectangle(frame_markers,(x0,y0),(x1,y1),[255,0,0],2)  #1\n",
    "        cv2.rectangle(frame_markers, (x0,y1),(x1,y2),[0,255,0],2)  #2\n",
    "        cv2.rectangle(frame_markers, (x0,y2),(x1,y3),[0,0,255],2)  #3\n",
    "        cv2.rectangle(frame_markers, (x1,y0),(x2,y1),[255,0,255],2)  #4\n",
    "        cv2.rectangle(frame_markers, (x1,y1),(x2,y2),[255,255,0],2)  #5\n",
    "        cv2.rectangle(frame_markers, (x1,y2),(x2,y3),[0,255,255],2)  #6\n",
    "        cv2.rectangle(frame_markers, (x2,y0),(x3,y1),[255,255,255],2)  #7\n",
    "        cv2.rectangle(frame_markers, (x2,y1),(x3,y2),[0,0,0],2)  #8\n",
    "        cv2.rectangle(frame_markers, (x2,y2),(x3,y3),[0,255,0],2)  #9\n",
    "        \n",
    "    cv2.imshow('',frame_markers),\n",
    "    if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "screen_cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "(208.0, 405.0)\n",
      "6\n",
      "(389.0, 398.0)\n",
      "11\n",
      "(481.0, 397.0)\n",
      "10\n",
      "(243.0, 308.0)\n",
      "5\n",
      "(243.0, 210.0)\n",
      "12\n",
      "(335.0, 143.0)\n",
      "7\n",
      "(331.0, 406.0)\n",
      "4\n",
      "(512.0, 312.0)\n",
      "3\n",
      "(501.0, 215.0)\n",
      "2\n",
      "(389.0, 149.0)\n",
      "8\n",
      "(473.0, 147.0)\n",
      "1\n",
      "(219.0, 136.0)\n"
     ]
    }
   ],
   "source": [
    "for i in ids:\n",
    "    print(i[0])\n",
    "    corner_index = np.where(ids == i)[0][0]\n",
    "    print(tuple(corners[corner_index][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn on all the cameras\n",
    "\n",
    "# Check that everything looks good\n",
    "#  (lights on, cameras on, if doing markers, markers detected)\n",
    "# - If anything is broken, save a log explaining what's wrong\n",
    "\n",
    "# Watch for movement (once still for 2 minutes, move on)\n",
    "# - If after 15 minutes nothing is still, save a log explaining what's wrong \n",
    "\n",
    "# Figure out which song to play\n",
    "\n",
    "# Start recording (wait 10 seconds) \n",
    "# Play Song\n",
    "\n",
    "# Stop Recording\n",
    "# Close cameras\n",
    "# Save Video\n",
    "\n",
    "# Check to make sure everything worked, if it did, save it to the log\n",
    "\n",
    "# Close everything out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "cap = cv2.VideoCapture(4)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        print('skipping...')\n",
    "        continue\n",
    "    cv2.imshow('0',frame)\n",
    "    if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "for c in range(4):\n",
    "    cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "n_cameras = 4\n",
    "caps = [[]] * 4\n",
    "for c in range(n_cameras):\n",
    "    caps[c] = cv2.VideoCapture(c)\n",
    "\n",
    "t_start = time.time()\n",
    "t_end = t_start + 60\n",
    "while time.time() < t_end:\n",
    "    for c in range(4):\n",
    "        ret, frame = caps[c].read()\n",
    "        cv2.imshow(str(c),frame)\n",
    "    if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "for c in range(4):\n",
    "    caps[c].release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [ * 4\n",
    "test_copy = np.copy(test)\n",
    "test[0] = 2\n",
    "print(test,test_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This also works, and detecting motion is the right approach. \n",
    "#(how long should they be relatively still? 1 minute)\n",
    "#(how still is relatively still?)\n",
    "\n",
    "#screen_cap = cv2.VideoCapture('./low_cages.mov')\n",
    "screen_cap = cv2.VideoCapture(0)\n",
    "\n",
    "aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_250)\n",
    "parameters =  aruco.DetectorParameters_create()\n",
    "\n",
    "ret0, frame0 = screen_cap.read()\n",
    "gray0 = cv2.cvtColor(frame0, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "kernel = np.ones((5,5),np.float32)/25\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "out1 = cv2.VideoWriter('output3.avi',fourcc, 20.0, (640,480))\n",
    "\n",
    "while True:\n",
    "    ret1, frame1 = screen_cap.read()\n",
    "    #frame = cv2.imread('tags.png')\n",
    "    if ret1 == True:\n",
    "        gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        continue\n",
    "    dst = cv2.filter2D(gray1,-1,kernel)\n",
    "    \n",
    "    dif = cv2.absdiff(gray1,gray0)\n",
    "    #dif = gray1 - gray0\n",
    "    #pdb.set_trace()\n",
    "    dif = np.abs(dif)\n",
    "    dif[dif < 5] = 0\n",
    "    \n",
    "    out1.write(dif)\n",
    "    motion = str(np.round(np.log(np.sum(dif)),2))\n",
    "    cv2.putText(dif,motion,(10,450),cv2.FONT_HERSHEY_SIMPLEX,1,255)\n",
    "    cv2.imshow('Motion',dif)\n",
    "    cv2.imshow('Original',frame1)\n",
    "    if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "        break\n",
    "    gray0 = np.copy(gray1)\n",
    "\n",
    "screen_cap.release()\n",
    "out1.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Id's 1, 4, 9, 12 are the corners, let's build a better image: \n",
    "%matplotlib notebook\n",
    "\n",
    "img = cv2.imread('trial_run0.png')\n",
    "plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_250)\n",
    "parameters =  aruco.DetectorParameters_create()\n",
    "frame = cv2.imread('tags.png')\n",
    "\n",
    "while True:\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    corners, ids, rejectedImgPoints = aruco.detectMarkers(gray, aruco_dict, parameters=parameters)\n",
    "    frame_markers = aruco.drawDetectedMarkers(frame.copy(), corners, ids)\n",
    "    if len(corners) > 1:\n",
    "        corner1, corner2 = corners[0],corners[1]\n",
    "        top_left = corner1[0][0]\n",
    "        bottom_right = corner2[0][2]\n",
    "        midpoint = np.mean([top_left,bottom_right],0)\n",
    "        cv2.circle(frame_markers, tuple(midpoint),10,(255,0,0),thickness=10)\n",
    "    cv2.imshow('',frame_markers)\n",
    "    if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([255., 215.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0,y0 = tuple(corners[1][0,0])\n",
    "x1 = corners[12][0,0,0]\n",
    "y1 = corners[5][0,0,1]\n",
    "y2 = corners[10][0,0,1]\n",
    "x2 = corners[2][0,0,0]\n",
    "y3 = corners[9][0,0,1]\n",
    "x3 = corners[8][0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
