{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Quick code to capture video, courtesy of opencv documentation\n",
    "This is becoming more of a platform, worth cleaning up \n",
    "\n",
    "Todo: \n",
    "Get audio working - X\n",
    "Get FPS for Video - X\n",
    "Synch up audio and video - This is a problem...possibly unsurmountable? \n",
    "Use some functions you philistine - X\n",
    "Clean up UI\n",
    "Move off jupyter: debug while we're at it\n",
    "It might be better to have openCV stop while recording, for simplicity\n",
    "-Yes, but it's nice to have it running, for Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting audio\n",
      "recording video...\n",
      "starting audio\n",
      "recording video...\n",
      "13.784816714659849\n",
      "saving clip....\n",
      "12.356336449372595\n",
      "saving clip....\n",
      "1552238457.784596\n",
      "1552238457.788982\n",
      "monitoring...\n",
      "1552238457.784596\n",
      "1552238457.788982\n",
      "monitoring...\n"
     ]
    }
   ],
   "source": [
    "# Quick code to capture video, courtesy of opencv documentation\n",
    "# This is becoming more of a platform, worth cleaning up \n",
    "# \n",
    "# Todo: \n",
    "# Synch up audio and video - This is a problem...possibly unsurmountable? \n",
    "# Clean up UI\n",
    "# Add debugging\n",
    "# Add Menu? - Set parameters, devices, bounding box, etc \n",
    "# Specify Audio output device - x\n",
    "# Play sound from file - x\n",
    "# Order sound playback (random? Set? Maybe based on date? \n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import subprocess\n",
    "import sys,os\n",
    "from subprocess import Popen, PIPE\n",
    "from PIL import Image\n",
    "import time, datetime \n",
    "import threading\n",
    "import pyaudio, wave\n",
    "\n",
    "RECORDING = False\n",
    "    \n",
    "def monitor_cam(cam_count = 1):\n",
    "    caps = [0] * cam_count\n",
    "    counts = [0] * cam_count\n",
    "    clips = [[]] * cam_count\n",
    "    rets = [0] * cam_count\n",
    "    frames = [0] * cam_count\n",
    "    grays = [0] * cam_count\n",
    "    subgrays = [0] * cam_count\n",
    "    subgrays2 = [0] * cam_count\n",
    "    for n in range(cam_count):\n",
    "        cam_name = 'Cam' + str(n)\n",
    "        cv2.namedWindow(cam_name)\n",
    "        caps[n] = cv2.VideoCapture(n)\n",
    "    \n",
    "    CONT = True\n",
    "    while(CONT):\n",
    "        for n in range(cam_count):\n",
    "            rets[n],frames[n] = caps[n].read()\n",
    "            grays[n] = cv2.cvtColor(frames[n], cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Mark the bounding box(es)\n",
    "            # this is probably horribly inefficient...\n",
    "            grays[n][99,1000:1100] = 0\n",
    "            grays[n][201,1000:1100] = 0\n",
    "            grays[n][100:200,999] = 0\n",
    "            grays[n][100:200,1101] = 0\n",
    "            \n",
    "            grays[n][99,100:200] = 0\n",
    "            grays[n][201,100:200] = 0\n",
    "            grays[n][100:200,99] = 0\n",
    "            grays[n][100:200,201] = 0\n",
    "            \n",
    "            subgrays[n] = grays[n][100:200,1000:1100]\n",
    "            subgrays2[n] = grays[n][100:200,100:200]\n",
    "            if subgrays[n].mean() < 100:\n",
    "                gray1 = True\n",
    "                grays[n][99,1000:1100] = 255\n",
    "                grays[n][201,1000:1100] = 255\n",
    "                grays[n][100:200,999] = 255\n",
    "                grays[n][100:200,1101] = 255\n",
    "            else:\n",
    "                gray1 = False\n",
    "            if  subgrays2[n].mean() < 100:\n",
    "                gray2 = True\n",
    "                grays[n][99,100:200] = 255\n",
    "                grays[n][201,100:200] = 255\n",
    "                grays[n][100:200,99] = 255\n",
    "                grays[n][100:200,201] = 255\n",
    "            else:\n",
    "                gray2 = False\n",
    "            if gray1 == True and gray2 == True:\n",
    "                counts[n] += 1\n",
    "                if counts[n] >= 50 and RECORDING == False:     \n",
    "                    #Add a ten second record function\n",
    "                    RECORDING == True\n",
    "                    record_AV(caps[n])\n",
    "                    counts[n] = 0\n",
    "                    \n",
    "                elif RECORDING == True:\n",
    "                    counts[n] = 0\n",
    "            else:\n",
    "                count = 0\n",
    "            cv2.imshow('Cam'+ str(n),grays[n])\n",
    "            if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "                CONT = False\n",
    "                \n",
    "    for n in range(cam_count):\n",
    "        caps[n].release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return\n",
    "\n",
    "## Wait some set amount and says a string\n",
    "def speak(phrase = \"Hi there\", wait = 2):\n",
    "    time.sleep(wait)\n",
    "    subprocess.call([\"say\",phrase])\n",
    "    return\n",
    "\n",
    "## Play some .wav from a file using a specified output device\n",
    "def play_wav(p_audio = pyaudio.PyAudio, wav_file = \"test.wav\", out_index = 1):\n",
    "    CHUNK = 1024\n",
    "    p = p_audio\n",
    "    wf = wave.open(wav_file, 'rb')\n",
    "    stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                    channels=wf.getnchannels(),\n",
    "                    rate=wf.getframerate(),\n",
    "                    output=True, \n",
    "                    output_device_index = out_index)\n",
    "    data = wf.readframes(CHUNK)\n",
    "    while len(data) > 0:\n",
    "        stream.write(data)\n",
    "        data = wf.readframes(CHUNK)\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    return\n",
    "\n",
    "def record_AV(cap, mic = None):\n",
    "    # Start Audio & Video, then play the sound\n",
    "    #print('booting up threads')\n",
    "    t = threading.Thread(target=speak)\n",
    "    #t = threading.Thread(target=play_wav,args(out_index=mic,) \n",
    "    #record_audio()\n",
    "    a = threading.Thread(target=record_audio, args=(10,mic,))\n",
    "    #record_video()\n",
    "    v = threading.Thread(target=record_video, args=(cap,))\n",
    "    \n",
    "    print('starting audio')\n",
    "    a.start()\n",
    "   \n",
    "    #print('starting video')\n",
    "    v.start() \n",
    "    \n",
    "    #print('playing sound')\n",
    "    t.start()\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    # Add a ~10s monitor so you see the posture\n",
    "    while(count<100):\n",
    "        ret0,frame0 = cap0.read()\n",
    "        ret1,frame1 = cap1.read()\n",
    "        \n",
    "        gray0 = cv2.cvtColor(frame0,cv2.COLOR_BGR2GRAY)\n",
    "        gray1 = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imshow('cam0',gray0)\n",
    "        cv2.imshow('cam1',gray1)\n",
    "        count += 1\n",
    "        cv2.waitKey(5)\n",
    "    \"\"\"\n",
    "    #The join stops it from continueing until it's done..\n",
    "    #a.join()\n",
    "    #v.join()\n",
    "    #t.join()\n",
    "    \n",
    "    return \n",
    "\n",
    "# Record and save audio\n",
    "# Defaults to default microphone, you'll need to know the specific index otherwise\n",
    "# There could be a way to automate it...\n",
    "def record_audio(length = 10,mic = None):\n",
    "    \n",
    "    #print('recording audio...')\n",
    "    p = pyaudio.PyAudio()\n",
    "    \n",
    "    if mic == None:\n",
    "        dev_index = 0\n",
    "    else:\n",
    "        dev_index = mic\n",
    "    device_info = p.get_device_info_by_index(dev_index)\n",
    "    \n",
    "    # Set Parameters\n",
    "    FRAMES_PERBUFF = 2048\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 1\n",
    "    FRAME_RATE = int(device_info['defaultSampleRate'])\n",
    "    # Boot up stream and populate data then close stream (I'll know the amount of time recording)\n",
    "    stream = p.open(format=FORMAT,channels=CHANNELS,rate=FRAME_RATE,input=True, input_device_index=mic,frames_per_buffer=FRAMES_PERBUFF)\n",
    "    frames = []\n",
    "\n",
    "    REC_SECONDS = length\n",
    "    nchunks = int(REC_SECONDS * FRAME_RATE / FRAMES_PERBUFF)\n",
    "    a_start = time.time()\n",
    "    for i in range(0, nchunks):\n",
    "        data = stream.read(FRAMES_PERBUFF)\n",
    "        frames.append(data)\n",
    "    a_stop = time.time()\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "\n",
    "    #print('saving audio...')\n",
    "    date_string = time.strftime(\"%Y-%m-%d-%H:%M\")\n",
    "    outfile = 'test_audio_' + date_string + \".wav\"\n",
    "    \n",
    "    wf = wave.open(outfile,'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(FRAME_RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    \n",
    "    global A_START\n",
    "    global A_FINISH\n",
    "    global A_TMP\n",
    "    A_START = a_start\n",
    "    A_FINISH = a_stop\n",
    "    A_TMP = outfile\n",
    "    return\n",
    "\n",
    "def record_video(cap):\n",
    "    print('recording video...')\n",
    "    clip = []\n",
    "    \"\"\"\n",
    "    v_0 = time.time()\n",
    "    ret,frame = cap.read()\n",
    "    clip.append(frame)\n",
    "    v_start = time.time()\n",
    "    cv2.waitKey(40)\n",
    "    v_wait = time.time()\n",
    "    ret,frame = cap.read()\n",
    "    clip.append(frame)\n",
    "    v_2 = time.time()\n",
    "    \n",
    "    print('time series:')\n",
    "    print(v_0)\n",
    "    print(v_start)\n",
    "    print(v_wait)\n",
    "    print(v_2)\n",
    "    \"\"\"\n",
    "    \n",
    "    v_start = time.time()\n",
    "    \n",
    "    vid_time = 10\n",
    "    while time.time() <= v_start + vid_time:\n",
    "        ret, frame = cap.read()\n",
    "        clip.append(frame)\n",
    "        cv2.waitKey(40)\n",
    "    \"\"\"    \n",
    "    while(len(clip) <= 300):\n",
    "        ret, frame = cap.read()\n",
    "        clip.append(frame)  \n",
    "        cv2.waitKey(40)\n",
    "    \"\"\"    \n",
    "    v_stop = time.time()\n",
    "    vid_length = v_stop - v_start\n",
    "    num_frames = len(clip)\n",
    "    fps = num_frames / vid_length\n",
    "    print(fps)\n",
    "    round_fps = int(round(fps))\n",
    "    global V_START\n",
    "    global V_FINISH\n",
    "    \n",
    "    V_START = v_start\n",
    "    V_FINISH = v_stop\n",
    "    \n",
    "    save_clip(clip,fps)\n",
    "\n",
    "    return\n",
    "\n",
    "def save_clip(clip,fps):\n",
    "    global RECORDING\n",
    "    print('saving clip....')\n",
    "    date_string = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "    outfile = 'test_vid' + date_string + \".avi\"\n",
    "    framerate = str(fps)\n",
    "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'mjpeg', \n",
    "               '-r', framerate, '-i', '-', '-vcodec', 'mpeg4', '-qscale', \n",
    "               '5', '-r', framerate, outfile], stdin=PIPE)\n",
    "    fps, duration = 20, len(clip) / 20.\n",
    "    for i in range(len(clip)):\n",
    "        col_im = cv2.cvtColor(clip[i],cv2.COLOR_BGR2RGB)\n",
    "        rot_im = np.rot90(col_im,3)\n",
    "        im = Image.fromarray(rot_im)\n",
    "        im.save(p.stdin, 'JPEG')\n",
    "    #print(clip[i])\n",
    "    p.stdin.close()\n",
    "    p.wait()\n",
    "    \n",
    "    global A_START,V_START, A_TMP\n",
    "    offset = V_START - A_START\n",
    "    print(V_START)\n",
    "    print(A_START)\n",
    "    a_file = A_TMP\n",
    "    splice_AV(a_file,outfile,offset)\n",
    "    RECORDING = False\n",
    "    print(\"monitoring...\")\n",
    "    return\n",
    "\n",
    "# Combine audio & video with calculated offset\n",
    "def splice_AV(a_file,v_file,offset):\n",
    "    outfile = 'av_' + v_file\n",
    "    \n",
    "    # quickly convert offset to time\n",
    "\n",
    "    p = Popen(['ffmpeg','-i',v_file, '-itsoffset', str(offset), \n",
    "           '-i', a_file, '-vcodec', 'copy', '-acodec', 'copy', outfile])\n",
    "    p.wait()\n",
    "    #Popen(['rm',a_file,v_file])\n",
    "    return\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    monitor_cam()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## In theory, this should work on a windows, but doesn't work on a mac\n",
    "\n",
    "height,width = clip[1].shape\n",
    "fourcc = cv2.cv.CV_FOURCC('M','J','P','G')\n",
    "video = cv2.VideoWriter('test.mpg',fourcc,10,(width,height),0)\n",
    "#write the video, reset the variables, leave the loop\n",
    "for i in range(len(clip)):\n",
    "    clip_color = cv2.cvtColor(clip[i], cv2.cv.CV_GRAY2RGB)\n",
    "    video.write(clip_color)\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Popen(['ffmpeg','-i','my_video.avi', '-itsoffset', str(d), \n",
    "       '-i', 'my_audio.wav', '-vcodec', 'copy', '-acodec', 'copy', 'output2.avi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "offset = V_START - A_START\n",
    "print offset\n",
    "print str(-offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s, ms = divmod(offset,1)\n",
    "m, s = divmod(offset, 60)\n",
    "h, m = divmod(m, 60)\n",
    "dt_offset = \"%02d:%02d:%f\" % (h, m, offset)\n",
    "\n",
    "dt_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44100\n"
     ]
    }
   ],
   "source": [
    "import pyaudio, wave\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "mic = 0\n",
    "if mic == None:\n",
    "    dev_index = 0\n",
    "else:\n",
    "    dev_index = mic\n",
    "device_info = p.get_device_info_by_index(dev_index)\n",
    "print int(device_info['defaultSampleRate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'defaultHighInputLatency': 0.1,\n",
       " 'defaultHighOutputLatency': 0.014036281179138322,\n",
       " 'defaultLowInputLatency': 0.01,\n",
       " 'defaultLowOutputLatency': 0.0038775510204081634,\n",
       " 'defaultSampleRate': 44100.0,\n",
       " 'hostApi': 0L,\n",
       " 'index': 1L,\n",
       " 'maxInputChannels': 0L,\n",
       " 'maxOutputChannels': 2L,\n",
       " 'name': u'Built-in Output',\n",
       " 'structVersion': 2L}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.get_default_output_device_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "mic = 0\n",
    "# Get some info if you need it\n",
    "\n",
    "def_info = p.get_default_input_device_info()\n",
    "host_info = p.get_default_host_api_info()\n",
    "device_info = p.get_device_info_by_index(0)\n",
    "\n",
    "# Set Parameters\n",
    "FRAMES_PERBUFF = 2048\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "FRAME_RATE = int(device_info['defaultSampleRate'])\n",
    "\n",
    "# Boot up stream and populate data then close stream (I'll know the amount of time recording)\n",
    "stream = p.open(format=FORMAT,channels=CHANNELS,rate=FRAME_RATE,input=True,input_device_index=mic,frames_per_buffer=FRAMES_PERBUFF)\n",
    "frames = []\n",
    "\n",
    "REC_SECONDS = 5\n",
    "nchunks = int(REC_SECONDS * FRAME_RATE / FRAMES_PERBUFF)\n",
    "for i in range(0, nchunks):\n",
    "    data = stream.read(FRAMES_PERBUFF)\n",
    "    frames.append(data)\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'defaultHighInputLatency': 0.1,\n",
       " 'defaultHighOutputLatency': 0.0126875,\n",
       " 'defaultLowInputLatency': 0.01,\n",
       " 'defaultLowOutputLatency': 0.0033541666666666668,\n",
       " 'defaultSampleRate': 48000.0,\n",
       " 'hostApi': 0L,\n",
       " 'index': 3,\n",
       " 'maxInputChannels': 1L,\n",
       " 'maxOutputChannels': 2L,\n",
       " 'name': u'CableCreation',\n",
       " 'structVersion': 2L}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Currently \n",
    "# 0 : Default Mic\n",
    "# 1 : Default Output\n",
    "# 2 : HDMI (Input/Output)\n",
    "# 3 : Cable Creation (Input/Output)\n",
    "import pyaudio\n",
    "p = pyaudio.PyAudio()\n",
    "p.get_device_info_by_index(3)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_stream = p.open(format = pyaudio.paInt16, channels=1, rate=44100, output=True, output_device_index = 1)\n",
    "\n",
    "for i in frames:\n",
    "    out_stream.write(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the file\n",
    "import wave\n",
    "wf = wave.open('test_auido.wav','wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "wf.setframerate(FRAME_RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# My first thread practice\n",
    "import threading \n",
    "import logging\n",
    "import time\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                   format='[%(levelname)s] (%(threadName)-10s) %(message)s',\n",
    "                   )\n",
    "def worker(id = \"Unknown\"):\n",
    "    logging.debug('Starting')\n",
    "    print \"Worker number: \" + str(id)\n",
    "    time.sleep(2)\n",
    "    logging.debug('Exiting')\n",
    "    return 0 \n",
    "\n",
    "def my_service():\n",
    "    logging.debug('Starting')\n",
    "    time.sleep(3)\n",
    "    logging.debug('Exiting')\n",
    "    \n",
    "t = threading.Thread(name='my_service',target=my_service)\n",
    "w = threading.Thread(name='Worker 1',target=worker,args=(1,))\n",
    "w2 = threading.Thread(target=worker)\n",
    "\n",
    "w.start()\n",
    "w2.start()\n",
    "t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Making a Daemon...\n",
    "# So a non-daemon still runs concurrently, it's just that the program has to wait until it's finished. \n",
    "# This distinction so far doesn't not seem critical in jupyter, but it does allow me to keep going. Which is rad\n",
    "def daemon():\n",
    "    logging.debug('daemon Starting')\n",
    "    time.sleep(5)\n",
    "    print 'I am many'\n",
    "    logging.debug('daemon Exiting')\n",
    "    \n",
    "d=threading.Thread(name='daemon', target=daemon)\n",
    "d.setDaemon(True)\n",
    "\n",
    "def non_daemon():\n",
    "    logging.debug('non daemon starting')\n",
    "    logging.debug('non daemon Exiting')\n",
    "    \n",
    "t = threading.Thread(name='non-daemon', target=non_daemon)\n",
    "\n",
    "d.start()\n",
    "t.start()\n",
    "\n",
    "print 'all done'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "def evens():\n",
    "    for e in range(10):\n",
    "        print str(2*e)\n",
    "        time.sleep(2)\n",
    "    return 1\n",
    "\n",
    "def odds():\n",
    "    for o in range(10):\n",
    "        print str(2*e -1)\n",
    "        time.sleep(1)\n",
    "    return 1\n",
    "\n",
    "e = threading.Thread(target=evens)\n",
    "o = threading.Thread(target=odds)\n",
    "\n",
    "e.start\n",
    "o.start\n",
    "\n",
    "while evens() != 1:\n",
    "    print \"I'm waiting...\"\n",
    "    time.sleep(3)\n",
    "    \n",
    "for i in range(5):\n",
    "    print \"I'm running ahead!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e = threading.Thread(target=evens)\n",
    "\n",
    "\n",
    "e.start()\n",
    "e.join()\n",
    "\n",
    "\n",
    "print \"Very Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
