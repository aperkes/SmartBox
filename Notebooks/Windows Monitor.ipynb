{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Script to run playback experiments: \n",
    "## Made by Ammon Perkes for use in Marc Schmidt's Lab\n",
    "## For questions, contact perkes.ammon@gmail.com\n",
    "\n",
    "## Plays and records from each camera in turn, and then closes. \n",
    "## The idea is to be booted by Schedule Tasks in windows: SchTasks /Create /SC DAILY /TN “My Task” /TR “C:RunMe.bat” /ST 09:00\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import subprocess\n",
    "import sys,os,shutil\n",
    "from subprocess import Popen, PIPE\n",
    "from PIL import Image\n",
    "import time, datetime \n",
    "import threading\n",
    "import pyaudio, wave\n",
    "\n",
    "RECORDING = False\n",
    "LOGS = {}\n",
    "LOGS[0] = 'BOX0.csv'\n",
    "LOGS[1] = 'BOX1.csv'\n",
    "LOGS[2] = 'BOX2.csv'\n",
    "LOGS[3] = 'BOX3.csv'\n",
    "\n",
    "OUTPUTS = {}\n",
    "OUTPUTS[0] = '1'\n",
    "OUTPUTS[1] = '2'\n",
    "OUTPUTS[2] = '3'\n",
    "OUTPUTS[3] = '4'\n",
    "\n",
    "## Advanced function which actually monitors the camera\n",
    "def monitor_cam(cam_count = 1):\n",
    "    caps = [0] * cam_count\n",
    "    counts = [0] * cam_count\n",
    "    clips = [[]] * cam_count\n",
    "    rets = [0] * cam_count\n",
    "    frames = [0] * cam_count\n",
    "    grays = [0] * cam_count\n",
    "    subgrays = [0] * cam_count\n",
    "    for n in range(cam_count):\n",
    "        cam_name = 'Cam' + str(n)\n",
    "        cv2.namedWindow(cam_name)\n",
    "        caps[n] = cv2.VideoCapture(n)\n",
    "    \n",
    "    CONT = True\n",
    "    while(CONT):\n",
    "        for n in range(cam_count):\n",
    "            rets[n],frames[n] = caps[n].read()\n",
    "            grays[n] = cv2.cvtColor(frames[n], cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Mark the bounding box\n",
    "            grays[n][99,1000:1100] = 0\n",
    "            grays[n][201,1000:1100] = 0\n",
    "            grays[n][100:200,999] = 0\n",
    "            grays[n][100:200,1101] = 0\n",
    "            \n",
    "            subgrays[n] = grays[n][100:200,1000:1100]\n",
    "            if subgrays[n].mean() < 100:\n",
    "                counts[n] += 1\n",
    "                grays[n][99,1000:1100] = 255\n",
    "                grays[n][201,1000:1100] = 255\n",
    "                grays[n][100:200,999] = 255\n",
    "                grays[n][100:200,1101] = 255\n",
    "                if counts[n] >= 50 and RECORDING == False:     \n",
    "                    #Add a ten second record function\n",
    "                    RECORDING == True\n",
    "                    record_AV(caps[n])\n",
    "                    counts[n] = 0\n",
    "                elif RECORDING == True:\n",
    "                    counts[n] = 0\n",
    "            else:\n",
    "                count = 0\n",
    "            cv2.imshow('Cam'+ str(n),grays[n])\n",
    "            if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "                CONT = False\n",
    "                \n",
    "    for n in range(cam_count):\n",
    "        caps[n].release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return\n",
    "\n",
    "## Simpler function which simply records blindly, checks every camera, and then exits\n",
    "def record_blind(cam_count = 1):\n",
    "    caps = [0] * cam_count\n",
    "    BLIND = True\n",
    "    counts = [0] * cam_count\n",
    "    clips = [[]] * cam_count\n",
    "    rets = [0] * cam_count\n",
    "    frames = [0] * cam_count\n",
    "    grays = [0] * cam_count\n",
    "    subgrays = [0] * cam_count\n",
    "    for n in range(cam_count):\n",
    "        cam_name = 'Cam' + str(n)\n",
    "        cv2.namedWindow(cam_name)\n",
    "        caps[n] = cv2.VideoCapture(n)\n",
    "    \n",
    "    CONT = True\n",
    "    while(CONT):\n",
    "        for n in range(cam_count):\n",
    "            rets[n],frames[n] = caps[n].read()\n",
    "            ## If Blind is set to True, just record and skip forward\n",
    "            if BLIND == True:\n",
    "                record_AV(caps[n],cam_id = n)\n",
    "                CONT = False\n",
    "                continue\n",
    "            \n",
    "            grays[n] = cv2.cvtColor(frames[n], cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "\n",
    "            # Mark the bounding box\n",
    "            grays[n][99,1000:1100] = 0\n",
    "            grays[n][201,1000:1100] = 0\n",
    "            grays[n][100:200,999] = 0\n",
    "            grays[n][100:200,1101] = 0\n",
    "            \n",
    "            subgrays[n] = grays[n][100:200,1000:1100]\n",
    "            if subgrays[n].mean() < 100:\n",
    "                counts[n] += 1\n",
    "                grays[n][99,1000:1100] = 255\n",
    "                grays[n][201,1000:1100] = 255\n",
    "                grays[n][100:200,999] = 255\n",
    "                grays[n][100:200,1101] = 255\n",
    "                if counts[n] >= 50 and RECORDING == False:     \n",
    "                    #Add a ten second record function\n",
    "                    RECORDING == True\n",
    "                    record_AV(caps[n],cam_id = n)\n",
    "                    counts[n] = 0\n",
    "                elif RECORDING == True:\n",
    "                    counts[n] = 0\n",
    "            else:\n",
    "                count = 0\n",
    "            cv2.imshow('Cam'+ str(n),grays[n])\n",
    "            if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "                CONT = False\n",
    "                \n",
    "    for n in range(cam_count):\n",
    "        caps[n].release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return    \n",
    "\n",
    "## Little function to speak. Handy for sound tests, or for freaking out your friends\n",
    "def speak(phrase = \"Hi there\", wait = 2):\n",
    "    time.sleep(wait)\n",
    "    subprocess.call([\"say\",phrase])\n",
    "    return\n",
    "\n",
    "## More advanced function which plays a specific sound to a specific output device. \n",
    "def play_sound_py(cam_id, song_name = 'BDY.wav', output_device = 1):\n",
    "    global OUTPUTS\n",
    "    \n",
    "    CHUNK = 1024\n",
    "\n",
    "    wf = wave.open(song_name, 'rb')\n",
    "    if output_device == 0:\n",
    "        output_devie = OUTPUTS[cam_id]\n",
    "    # instantiate PyAudio (1)\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    # open stream (2)\n",
    "    stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                    channels=wf.getnchannels(),\n",
    "                    rate=wf.getframerate(),\n",
    "                    output_device_index = output_device,\n",
    "                    output=True)\n",
    "    # read data\n",
    "    data = wf.readframes(CHUNK)\n",
    "\n",
    "    # play stream (3)\n",
    "    while len(data) > 0:\n",
    "        stream.write(data)\n",
    "        data = wf.readframes(CHUNK)\n",
    "\n",
    "    # stop stream (4)\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "\n",
    "    # close PyAudio (5)\n",
    "    p.terminate()\n",
    "    return 0\n",
    "\n",
    "## As above, but finds a specific song (I could probably roll these two into one, but whatever.)\n",
    "def play_song_py(cam_id, output_device = 1, wait = 2):\n",
    "    global OUTPUTS\n",
    "    if output_device == 0:\n",
    "        output_device = OUTPUTS[cam_id]\n",
    "    time.sleep(wait)\n",
    "    song_name = get_song(cam_id)\n",
    "    CHUNK = 1024\n",
    "\n",
    "    wf = wave.open('BDY_right.wav', 'rb')\n",
    "\n",
    "    # instantiate PyAudio (1)\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    # open stream (2)\n",
    "    stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                    channels=wf.getnchannels(),\n",
    "                    rate=wf.getframerate(),\n",
    "                    output_device_index = output_device,\n",
    "                    output=True)\n",
    "    # read data\n",
    "    data = wf.readframes(CHUNK)\n",
    "\n",
    "    # play stream (3)\n",
    "    while len(data) > 0:\n",
    "        stream.write(data)\n",
    "        data = wf.readframes(CHUNK)\n",
    "\n",
    "    # stop stream (4)\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "\n",
    "    # close PyAudio (5)\n",
    "    p.terminate()\n",
    "    return 0\n",
    "\n",
    "## Simple function which plays a song out of the default output device\n",
    "def play_song(cam_id, wait = 2):\n",
    "    time.sleep(wait)\n",
    "    song_name = get_song(cam_id)\n",
    "\n",
    "    #winsound.PlaySound(song_name, winsound.SND_FILENAME)\n",
    "    return_code = subprocess.call([\"afplay\", song_name])\n",
    "    \n",
    "    print song_name\n",
    "    return \n",
    "\n",
    "## Function for finding the correct song for the cam_id, based on a somewhat involved .csv\n",
    "def get_song(cam_id):\n",
    "    global LOGS\n",
    "    logs = LOGS\n",
    "    bird_name = 0\n",
    "    log_name = logs[cam_id]\n",
    "    r_log = open(log_name,'r')\n",
    "    tmp_log = open('tmp.csv','w')\n",
    "    #NOTE: this could be cleaner\n",
    "    unplayed = 1\n",
    "    for line in r_log:\n",
    "        split_line = line.strip().split(',')\n",
    "        if split_line[-1] != '0':\n",
    "            tmp_log.write(line + '\\n')\n",
    "        elif split_line[-1] == '0' and unplayed:\n",
    "            print 'I found a line!'\n",
    "            bird_name = split_line[1]\n",
    "            split_line[-1] = str(datetime.datetime.now())\n",
    "            tmp_log.write(\",\".join(split_line) + '\\n')\n",
    "            unplayed = 0\n",
    "        else:\n",
    "            tmp_log.write(line + '\\n')\n",
    "    print 'No more unplayed songs found'\n",
    "    r_log.close()\n",
    "    tmp_log.close()\n",
    "    # Save tmp_log as r_log\n",
    "    shutil.move('tmp.csv',log_name)\n",
    "    if cam_id % 2 == 0:\n",
    "        side = '_right.wav'\n",
    "    else:\n",
    "        side = '_left.wav'\n",
    "    song_name = bird_name + side  \n",
    "    return song_name\n",
    "\n",
    "## Runs the AV recording, including playing a song. \n",
    "def record_AV(cap, mic = None, cam_id = 0):\n",
    "    # Start Audio & Video, then play the sound\n",
    "    #print 'booting up threads'\n",
    "    #t = threading.Thread(target=speak)\n",
    "    t = threading.Thread(target=play_song,args=(cam_id,))\n",
    "    #record_audio()\n",
    "    a = threading.Thread(target=record_audio, args=(10,mic,))\n",
    "    #record_video()\n",
    "    v = threading.Thread(target=record_video, args=(cap,))\n",
    "    \n",
    "    print 'starting audio'\n",
    "    a.start()\n",
    "   \n",
    "    #print 'starting video'\n",
    "    v.start() \n",
    "    \n",
    "    #print 'playing sound'\n",
    "    t.start()\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    # Add a ~10s monitor so you see the posture\n",
    "    while(count<100):\n",
    "        ret0,frame0 = cap0.read()\n",
    "        ret1,frame1 = cap1.read()\n",
    "        \n",
    "        gray0 = cv2.cvtColor(frame0,cv2.COLOR_BGR2GRAY)\n",
    "        gray1 = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imshow('cam0',gray0)\n",
    "        cv2.imshow('cam1',gray1)\n",
    "        count += 1\n",
    "        cv2.waitKey(5)\n",
    "    \"\"\"\n",
    "    #The join stops it from continueing until it's done..\n",
    "    a.join()\n",
    "    v.join()\n",
    "    t.join()\n",
    "    \n",
    "    return \n",
    "\n",
    "# Record and save audio\n",
    "# Defaults to default microphone, you'll need to know the specific index otherwise\n",
    "# There could be a way to automate it...\n",
    "def record_audio(length = 10,mic = None):\n",
    "    \n",
    "    #print 'recording audio...'\n",
    "    p = pyaudio.PyAudio()\n",
    "    \n",
    "    if mic == None:\n",
    "        dev_index = 0\n",
    "    else:\n",
    "        dev_index = mic\n",
    "    device_info = p.get_device_info_by_index(dev_index)\n",
    "    \n",
    "    # Set Parameters\n",
    "    FRAMES_PERBUFF = 2048\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 1\n",
    "    FRAME_RATE = int(device_info['defaultSampleRate'])\n",
    "\n",
    "    # Boot up stream and populate data then close stream (I'll know the amount of time recording)\n",
    "    stream = p.open(format=FORMAT,channels=CHANNELS,rate=FRAME_RATE,input=True, input_device_index=mic,frames_per_buffer=FRAMES_PERBUFF)\n",
    "    frames = []\n",
    "\n",
    "    REC_SECONDS = length\n",
    "    nchunks = int(REC_SECONDS * FRAME_RATE / FRAMES_PERBUFF)\n",
    "    a_start = time.time()\n",
    "    for i in range(0, nchunks):\n",
    "        data = stream.read(FRAMES_PERBUFF)\n",
    "        frames.append(data)\n",
    "    a_stop = time.time()\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "\n",
    "    #print 'saving audio...'\n",
    "    date_string = time.strftime(\"%Y-%m-%d-%H:%M\")\n",
    "    outfile = 'test_audio_' + date_string + \".wav\"\n",
    "    \n",
    "    wf = wave.open(outfile,'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(FRAME_RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    \n",
    "    global A_START\n",
    "    global A_FINISH\n",
    "    global A_TMP\n",
    "    A_START = a_start\n",
    "    A_FINISH = a_stop\n",
    "    A_TMP = outfile\n",
    "    return\n",
    "\n",
    "def record_video(cap):\n",
    "    print 'recording video...'\n",
    "    clip = []\n",
    "    \"\"\"\n",
    "    v_0 = time.time()\n",
    "    ret,frame = cap.read()\n",
    "    clip.append(frame)\n",
    "    v_start = time.time()\n",
    "    cv2.waitKey(40)\n",
    "    v_wait = time.time()\n",
    "    ret,frame = cap.read()\n",
    "    clip.append(frame)\n",
    "    v_2 = time.time()\n",
    "    \n",
    "    print 'time series:'\n",
    "    print v_0\n",
    "    print v_start\n",
    "    print v_wait\n",
    "    print v_2\"\"\"\n",
    "    \n",
    "    v_start = time.time()\n",
    "    \n",
    "    vid_time = 10\n",
    "    while time.time() <= v_start + vid_time:\n",
    "        ret, frame = cap.read()\n",
    "        clip.append(frame)\n",
    "        cv2.waitKey(40)\n",
    "    \"\"\"    \n",
    "    while(len(clip) <= 300):\n",
    "        ret, frame = cap.read()\n",
    "        clip.append(frame)  \n",
    "        cv2.waitKey(40)\n",
    "    \"\"\"    \n",
    "    v_stop = time.time()\n",
    "    vid_length = v_stop - v_start\n",
    "    num_frames = len(clip)\n",
    "    fps = num_frames / vid_length\n",
    "    print fps\n",
    "    round_fps = int(round(fps))\n",
    "    global V_START\n",
    "    global V_FINISH\n",
    "    \n",
    "    V_START = v_start\n",
    "    V_FINISH = v_stop\n",
    "    \n",
    "    save_clip(clip,fps)\n",
    "\n",
    "    return\n",
    "\n",
    "def save_clip(clip,fps):\n",
    "    global RECORDING\n",
    "    print 'saving clip....'\n",
    "    date_string = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "    outfile = 'test_vid' + date_string + \".avi\"\n",
    "    framerate = str(fps)\n",
    "    p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'mjpeg', \n",
    "               '-r', framerate, '-i', '-', '-vcodec', 'mpeg4', '-qscale', \n",
    "               '5', '-r', framerate, outfile], stdin=PIPE)\n",
    "    fps, duration = 20, len(clip) / 20.\n",
    "    for i in range(len(clip)):\n",
    "        col_im = cv2.cvtColor(clip[i],cv2.COLOR_BGR2RGB)\n",
    "        rot_im = np.rot90(col_im,3)\n",
    "        im = Image.fromarray(rot_im)\n",
    "        im.save(p.stdin, 'JPEG')\n",
    "    #print clip[i]\n",
    "    p.stdin.close()\n",
    "    p.wait()\n",
    "    \n",
    "    global A_START,V_START, A_TMP\n",
    "    offset = V_START - A_START\n",
    "    print V_START\n",
    "    print A_START\n",
    "    a_file = A_TMP\n",
    "    splice_AV(a_file,outfile,offset)\n",
    "    RECORDING = False\n",
    "    #print \"monitoring...\"\n",
    "    return\n",
    "\n",
    "# Combine audio & video with calculated offset\n",
    "# NOTE: this is tricky, and does not work well on apple, as far as I can tell. \n",
    "# There seems to be a better function for windows. \n",
    "\n",
    "def splice_AV(a_file,v_file,offset):\n",
    "    outfile = 'av_' + v_file\n",
    "    \n",
    "    # quickly convert offset to time\n",
    "\n",
    "    p = Popen(['ffmpeg','-i',v_file, '-itsoffset', str(offset), \n",
    "           '-i', a_file, '-vcodec', 'copy', '-acodec', 'copy', outfile])\n",
    "    p.wait()\n",
    "    #Popen(['rm',a_file,v_file])\n",
    "    return\n",
    "\n",
    "## A little function to test cameras and microphones, since those id's are hard coded.\n",
    "def AV_test(cam_id = 0, output_id = 1):\n",
    "    #stream camera\n",
    "    cam_name = 'Cam' + str(cam_id)\n",
    "    cv2.namedWindow(cam_name)\n",
    "    cap = cv2.VideoCapture(cam_id)\n",
    "    CONT = True\n",
    "    while(CONT):\n",
    "        ret,frame = cap.read()\n",
    "        grayscale = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        cv2.imshow(cam_name,grayscale)\n",
    "        if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "            CONT = False\n",
    "        if cv2.waitKey(100) & 0xFF == ord('p'):\n",
    "            play_sound_py(output_id)\n",
    "            #t = threading.Thread(target=speak)\n",
    "            #t.start()\n",
    "    #wait for keypress space : speak\n",
    "    #wait for keypress q : quit\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #monitor_cam()\n",
    "    #record_blind()\n",
    "    #play_song_py(0)\n",
    "    #AV_test()\n",
    "    pass           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = pyaudio.PyAudio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p.get"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
